{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_LEN = 10000\n",
    "\n",
    "def load_data(func):\n",
    "    data = []\n",
    "    for i in range (DATA_LEN):\n",
    "        data.append(func(i))\n",
    "    return pandas.DataFrame(data)\n",
    "\n",
    "def split_data(data):\n",
    "    return numpy.split(data, [int(.8*len(data))])\n",
    "\n",
    "data_sin = load_data(lambda i: math.sin(i*0.01))\n",
    "data_sinx = load_data(lambda i: math.sin(i*0.01)*(i*0.01))\n",
    "\n",
    "train_data_sin, test_data_sin = split_data(data_sin)\n",
    "train_data_sinx, test_data_sinx = split_data(data_sinx)\n",
    "\n",
    "train_data_sin.plot()\n",
    "test_data_sin.plot()\n",
    "\n",
    "train_data_sinx.plot()\n",
    "test_data_sinx.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.as_default()\n",
    "writer = tf.summary.FileWriter(\"/tmp/tensorflowlogs\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, input_len, x, y, actual_activation, cost):\n",
    "        self.input_len = input_len\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.actual_activation = actual_activation\n",
    "        self.cost = cost\n",
    "\n",
    "def model_fully_connected(input_len):\n",
    "    x = tf.placeholder(\"float\", shape=(None, input_len))\n",
    "    y = tf.placeholder(\"float\", shape=(None, 1))\n",
    "    W = tf.Variable(tf.zeros([input_len, 1]))\n",
    "    b = tf.Variable(tf.zeros([1, 1]))\n",
    "    actual_activation = tf.matmul(x, W) + b\n",
    "    cost = tf.sqrt(tf.reduce_sum(tf.square(y - actual_activation)))\n",
    "    \n",
    "    return Model(input_len, x, y, actual_activation, cost)\n",
    "\n",
    "def model_convolution(input_len, kernel_size, num_filters):\n",
    "    x = tf.placeholder(\"float\", shape=(None, input_len))\n",
    "    xshaped = tf.reshape(x, [-1, input_len, 1])\n",
    "    y = tf.placeholder(\"float\", shape=(None, 1))\n",
    "    conv1 = tf.layers.conv1d(\n",
    "            inputs=xshaped,\n",
    "            kernel_size=kernel_size,\n",
    "            activation=tf.nn.relu,\n",
    "            strides=1,\n",
    "            filters=num_filters,\n",
    "            padding=\"VALID\")\n",
    "    dimensions_for_fully_connected = (int)(num_filters*(input_len-(kernel_size))/2)\n",
    "    max_pool = tf.reshape(\n",
    "        tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='VALID'),\n",
    "        [-1, dimensions_for_fully_connected]\n",
    "    )\n",
    "    W = tf.Variable(tf.zeros([dimensions_for_fully_connected, 1]))\n",
    "    b = tf.Variable(tf.zeros([1, 1]))\n",
    "    actual_activation = tf.matmul(max_pool, W) + b\n",
    "    cost = tf.sqrt(tf.reduce_sum(tf.square(y - actual_activation)))\n",
    "    \n",
    "    return Model(input_len, x, y, actual_activation, cost)\n",
    "\n",
    "def model_lstm(input_len, num_units):\n",
    "    inputs = tf.placeholder(tf.float32, [None, input_len])\n",
    "    inputs2 = tf.reshape(inputs, [-1, input_len, 1])\n",
    "    correct_output = tf.placeholder(tf.float32, [None, 1])\n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(num_units)])\n",
    "    x_ = tf.unstack(inputs2, axis=1, num=input_len)\n",
    "    output, layers = tf.contrib.rnn.static_rnn(stacked_lstm, x_, dtype=dtypes.float32)\n",
    "    output = output[-1]\n",
    "    prediction = tf.layers.dense(output, 1, activation=None)\n",
    "    loss = tf.sqrt(tf.reduce_sum(tf.square(correct_output - prediction)))\n",
    "    \n",
    "    return Model(input_len, inputs, correct_output, prediction, loss)\n",
    "\n",
    "def train(model, training_data, learning_rate, num_epochs=1):\n",
    "    start = time.time()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(model.cost)\n",
    "    print(\"Training.\")\n",
    "    tf.global_variables_initializer().run()\n",
    "    for j in range(num_epochs):\n",
    "        for i in range(len(training_data.index)-(model.input_len + 1)): \n",
    "            batch_xs = training_data.iloc[i:i+model.input_len].T.values\n",
    "            batch_ys = [training_data.iloc[i+model.input_len + 1].values]\n",
    "            sess.run(optimizer, feed_dict={model.x: batch_xs, model.y: batch_ys})\n",
    "        print(\"Epoch: \", j)\n",
    "    end = time.time()\n",
    "    print(\"Training done:\", end - start, \"s\")\n",
    "    \n",
    "def train_full_batch(model, training_data, optimizer_name, learning_rate, num_epochs):\n",
    "    start = time.time()\n",
    "    if optimizer_name == \"adagrad\":\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(model.cost)\n",
    "    else:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(model.cost) \n",
    "    print(\"Training.\")\n",
    "    tf.global_variables_initializer().run()\n",
    "    batch_xs = []\n",
    "    batch_ys = []\n",
    "    for i in range(len(training_data.index)-(model.input_len + 1)):\n",
    "        batch_xs.append(training_data.iloc[i:i+model.input_len].T.values[0])\n",
    "        batch_ys.append(training_data.iloc[i+model.input_len+1].values)\n",
    "    for j in range(num_epochs):\n",
    "        sess.run(optimizer, feed_dict={model.x: batch_xs, model.y: batch_ys})\n",
    "        if j % 100 == 0:\n",
    "            print(\"Epoch: \", j)\n",
    "    end = time.time()\n",
    "    print(\"Training done:\", end - start, \"s\")\n",
    "\n",
    "def group_list(l, group_size):\n",
    "    for i in range(0, len(l), group_size):\n",
    "        yield l[i:i+group_size]\n",
    "    \n",
    "def train_batch(model, training_data, optimizer_name, learning_rate, batch_size, num_epochs):\n",
    "    start = time.time()\n",
    "    if optimizer_name == \"adagrad\":\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate).minimize(model.cost)\n",
    "    else:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(model.cost) \n",
    "    print(\"Training.\")\n",
    "    tf.global_variables_initializer().run()\n",
    "    all_xs = []\n",
    "    all_ys = []\n",
    "    num_inputs = len(training_data.index)-(model.input_len + 1)\n",
    "    for i in range(num_inputs):\n",
    "        all_xs.append(training_data.iloc[i:i+model.input_len].T.values[0])\n",
    "        all_ys.append(training_data.iloc[i+model.input_len+1].values)\n",
    "    batch_xs = list(group_list(all_xs, batch_size))\n",
    "    batch_ys = list(group_list(all_ys, batch_size))\n",
    "    for j in range(num_epochs):\n",
    "        for i in range(num_inputs // batch_size):\n",
    "            sess.run(optimizer, feed_dict={model.x: batch_xs[i], model.y: batch_ys[i]})\n",
    "        if j % 100 == 0:\n",
    "            print(\"Epoch: \", j)\n",
    "    end = time.time()\n",
    "    print(\"Training done:\", end - start, \"s\")\n",
    "    \n",
    "def replicate(model, input_data):\n",
    "    test_input_x = []\n",
    "    test_input_y = []\n",
    "    for i in range(len(input_data.index)-(model.input_len + 1)):\n",
    "        test_input_x.append(input_data.iloc[i:i+model.input_len].T.values[0])\n",
    "        test_input_y.append(input_data.iloc[i+model.input_len+1].values)\n",
    "    predictions_evaluated = model.actual_activation.eval(\n",
    "        {model.x: test_input_x}\n",
    "    )\n",
    "    accuracy = tf.reduce_sum(tf.squared_difference (model.actual_activation, model.y))\n",
    "    squared_diff = accuracy.eval({model.x: test_input_x, model.y: test_input_y})\n",
    "    return pandas.DataFrame(numpy.concatenate((test_input_x[0], numpy.array(predictions_evaluated).flatten()))), squared_diff\n",
    "    \n",
    "def predict(model, input_data, steps):\n",
    "    test_input_x = input_data.iloc[0:model.input_len].T.values.copy()\n",
    "    predictions_evaluated = test_input_x[0].tolist()\n",
    "    acc_sum = 0\n",
    "    for i in range(steps):\n",
    "        new_prediction = model.actual_activation.eval({model.x: test_input_x})[0]\n",
    "        predictions_evaluated.extend (new_prediction)\n",
    "        test_input_x[0] = numpy.concatenate((test_input_x[0][1:], numpy.array(new_prediction)))\n",
    "        if (i < len(input_data)-(model.input_len+1)):\n",
    "            acc_sum += (input_data.iloc[i+model.input_len][0] - new_prediction)**2\n",
    "    return pandas.DataFrame(predictions_evaluated), acc_sum\n",
    "\n",
    "def stats(model, train_data, test_data, steps):\n",
    "    replicated_train, repl_error_train = replicate(model, train_data)\n",
    "    replicated_test, repl_error_test = replicate(model, test_data)\n",
    "    predicted_test, pred_error_test = predict(model, test_data, steps)\n",
    "    print(\"Squared replication error (train loss):\", repl_error_train)\n",
    "    replicated_train.plot()\n",
    "    print(\"Squared replication error (test loss):\", repl_error_test)\n",
    "    replicated_test.plot()\n",
    "    print(\"Squared prediction error (test loss):\", pred_error_test)\n",
    "    predicted_test.plot()\n",
    "    \n",
    "def direct_compare(model, test_data):\n",
    "    batch_xs = []\n",
    "    batch_ys = []\n",
    "    for i in range(len(test_data.index)-(model.input_len + 1)):\n",
    "        batch_xs.append(test_data.iloc[i:i+model.input_len].T.values[0])\n",
    "        batch_ys.append(test_data.iloc[i+model.input_len+1].values)\n",
    "\n",
    "    predictions = model.actual_activation.eval(feed_dict={lstm_model.x: batch_xs})\n",
    "\n",
    "    plot_predicted, = plt.plot(predictions, label='predicted')\n",
    "    plot_test, = plt.plot(batch_ys, label='train')\n",
    "    plt.legend(handles=[plot_predicted, plot_test])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model = model_fully_connected(200)\n",
    "train(fully_connected_model, train_data_sin, 0.001, 20)\n",
    "stats(fully_connected_model, train_data_sin, test_data_sin, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected_model2 = model_fully_connected(200)\n",
    "train_batch(fully_connected_model2, train_data_sinx, \"default\", 0.000001, 100, 200)\n",
    "stats(fully_connected_model2, train_data_sinx, test_data_sinx, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutional_model = model_convolution(200, 20, 10)\n",
    "train(convolutional_model, train_data_sin, 0.001, 20)\n",
    "stats(convolutional_model, train_data_sin, test_data_sin, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutional_model2 = model_convolution(200, 10, 5)\n",
    "train_batch(convolutional_model2, train_data_sinx, \"default\", 0.00001, 100, 300)\n",
    "stats(convolutional_model2, train_data_sinx, test_data_sinx, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = model_lstm(100, 128) # 5,3 / 10,10\n",
    "train_batch(lstm_model, train_data_sin, \"adagrad\", 0.01, 100, 5) # 0.1 1000 /\n",
    "stats(lstm_model, train_data_sin, test_data_sin, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
